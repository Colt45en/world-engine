# ğŸŒ World Engine Studio

A unified lexicon processing and semantic analysis system with integrated recording, chat interface, and real-time analysis capabilities.

## ğŸš€ Quick Start

```bash
# 1. Clone the repository
git clone https://github.com/YOUR_USERNAME/world-engine-studio.git
cd world-engine-studio

# 2. Install dependencies
pip install -r requirements.txt
python -m spacy download en_core_web_sm

# 3. Launch the studio
python launch_studio.py
```

Open http://localhost:8000/web/studio.html

## âœ¨ Features

- **ğŸ¤ Recording Studio** - Audio/video capture with timeline markers
- **ğŸ’¬ AI Chat Interface** - Command-driven workflow control
- **ğŸŒ World Engine** - Advanced lexicon analysis and semantic scaling
- **ğŸ”— Event Bridge** - Real-time component communication
- **ğŸ“Š Data Integration** - Automatic linking of recordings to analysis runs
- **ğŸ¯ Voice Commands** - Speech-to-command processing

## ğŸ—ï¸ Architecture

```
ğŸ“± Chat Controller â† â†’ ğŸ™ï¸ Recorder
       â†•ï¸
ğŸŒ World Engine (Lexicon Analysis)
       â†•ï¸
ğŸ“Š External Store (Persistent Data)
```

## ğŸ® Usage

### Web Interface (Recommended)
```bash
python -m world_engine_unified.main server
```
- Open http://localhost:8000/web/worldengine.html
- API docs at http://localhost:8000/docs

### Command Line Interface
```bash
python -m world_engine_unified.main cli
```

### Interactive Demo
```bash
python -m world_engine_unified.main demo
```

## Project Structure

```
world_engine_unified/
â”œâ”€â”€ __init__.py              # Main package
â”œâ”€â”€ main.py                  # Entry point launcher
â”œâ”€â”€ demo.py                  # Demo script
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ scales/                  # Semantic scaling
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ seeds.py            # Hand-labeled seed words
â”‚   â”œâ”€â”€ graph.py            # Synonym/antonym graphs
â”‚   â”œâ”€â”€ isotonic.py         # Order-preserving calibration
â”‚   â”œâ”€â”€ embeddings.py       # Neighbor expansion
â”‚   â””â”€â”€ typescores.py       # Type-level vectors
â”œâ”€â”€ context/                 # NLP processing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ parser.py           # spaCy pipeline
â”‚   â”œâ”€â”€ rules.py            # Linguistic rules
â”‚   â”œâ”€â”€ senses.py           # Sense disambiguation
â”‚   â”œâ”€â”€ sarcasm.py          # Sarcasm detection
â”‚   â”œâ”€â”€ domains.py          # Domain adaptation
â”‚   â””â”€â”€ scorer.py           # Token scoring
â”œâ”€â”€ api/                     # FastAPI service
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ service.py          # REST endpoints
â”œâ”€â”€ web/                     # Web interfaces
â”‚   â”œâ”€â”€ worldengine.html    # Main lexicon interface
â”‚   â””â”€â”€ word_engine_init.js # Initialization
â”œâ”€â”€ config/                  # Configuration files
â”‚   â”œâ”€â”€ toggle_schema.json  # View definitions
â”‚   â””â”€â”€ versions.json       # Version tracking
â””â”€â”€ data/                    # Data storage
    â””â”€â”€ (CSV files, vectors)
```

## Key Features

- **Seed-based Scoring**: Hand-labeled words with semantic values
- **Contextual Analysis**: spaCy-powered linguistic processing
- **Web Interface**: Interactive lexicon exploration
- **REST API**: Programmatic access to all features
- **Configurable Views**: Toggle between lexicon and runes modes
- **Extensible**: Modular design for easy enhancement

## API Endpoints

- `POST /score_word` - Score individual words
- `POST /score_token` - Analyze text tokens
- `POST /scale_between` - Compare word scales
- `GET /seeds` - Get seed words and constraints
- `GET /health` - System health check

## Configuration

Edit `config/toggle_schema.json` to customize:
- Data source paths
- View definitions
- Column mappings
- Default settings
